{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8dafe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmrl\n",
    "import time\n",
    "import matplotlib.pyplot as plts\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb30790b",
   "metadata": {},
   "source": [
    "Hemos configurado config.json para que nos devuelva el entorno TM20LIDAR \n",
    "\n",
    " \"ENV\": {\n",
    "    \"RTGYM_INTERFACE\": \"TM20LIDAR\", \n",
    "    \"WINDOW_WIDTH\": 958, \n",
    "    \"WINDOW_HEIGHT\": 488,  \n",
    "    \"SLEEP_TIME_AT_RESET\": 1.5, \n",
    "    \"IMG_HIST_LEN\": 4,\n",
    "    \"IMG_WIDTH\": 64,  \n",
    "    \"IMG_HEIGHT\": 64, \n",
    "    \"IMG_GRAYSCALE\": true, \n",
    "    \"RTGYM_CONFIG\": {\n",
    "      \"time_step_duration\": 0.05,  \n",
    "      \"start_obs_capture\": 0.04,  \n",
    "      \"time_step_timeout_factor\": 1.0,  \n",
    "      \"act_buf_len\": 2,  \n",
    "      \"benchmark\": false,  \n",
    "      \"wait_on_done\": true,  \n",
    "      \"ep_max_length\": 2000\n",
    "    },\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af713ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space:\t Tuple(Box(0.0, 1000.0, (1,), float32), Box(0.0, inf, (4, 19), float32), Box(-1.0, 1.0, (3,), float32), Box(-1.0, 1.0, (3,), float32))\n",
      "Action Space:\t\t Box(-1.0, 1.0, (3,), float32)\n",
      "observation space dim: None\n"
     ]
    }
   ],
   "source": [
    "env = tmrl.get_environment()\n",
    "print('Observation Space:\\t', env.observation_space)\n",
    "print('Action Space:\\t\\t', env.action_space)\n",
    "print(\"observation space dim:\", env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f725df65",
   "metadata": {},
   "source": [
    "De aquí podemos extraer que el espacio de observaciones es una tupla de 4 tipos de observación, cada una con sus características. La primera se refiere a la velocidad. La segunda, se refiere a los datos LIDAR que nos dan (tenemos las últimas 4 mediciones y 19 mediciones por cada una, ya que utiliza 19 rayos LIDAR). El espacio de observaciones nos devuelve tambien las dos últimas acciones. \n",
    "Las acciones se denotan como un espacio continuo de 3 mediciones, que son gas, frenado, y un espacio continuo entre -1.0 y 1.0 que denota la posición de las ruedas (si es 0 vamos rectos, -1.0 giramos a la izquierda y 1.0 giramos a la derecha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c98cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de observaciones : 83\n",
      "Número de acciones:\t 3\n"
     ]
    }
   ],
   "source": [
    "observation_space = np.sum([np.prod(value.shape) for value in env.observation_space])\n",
    "action_space = env.action_space.shape[0]\n",
    "print('Número de observaciones :', observation_space)\n",
    "print('Número de acciones:\\t', action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b16a69b",
   "metadata": {},
   "source": [
    "Efectivamente, tenemos 83 observaciones (1+4*19+3+3, que corresponden a velocidad, medidas LIDAR de los últimos 4 estados, y las 3 mediciones de las últimas dos acciones). \n",
    "El espacio de acciones son 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1aed8",
   "metadata": {},
   "source": [
    "Ahora nos fijaremos en como TMRL computa las recompensas. En nuestro caso, la interfaz TM2020 inicializa la recompensa como una clase así:\n",
    "\n",
    "self.reward_function = RewardFunction(reward_data_path=cfg.REWARD_PATH,\n",
    "                        nb_obs_forward=cfg.REWARD_CONFIG['CHECK_FORWARD'],\n",
    "                        nb_obs_backward=cfg.REWARD_CONFIG['CHECK_BACKWARD'],\n",
    "                        nb_zero_rew_before_failure=cfg.REWARD_CONFIG['FAILURE_COUNTDOWN'],\n",
    "                        min_nb_steps_before_failure=cfg.REWARD_CONFIG['MIN_STEPS'],\n",
    "                        max_dist_from_traj=cfg.REWARD_CONFIG['MAX_STRAY'])\n",
    "\n",
    "Y nuestro config incluye estos datos de recompensa:\n",
    "\n",
    "\"REWARD_CONFIG\": {\n",
    "    \"END_OF_TRACK\": 100.0,  \n",
    "    \"CONSTANT_PENALTY\": 0.0, \n",
    "    \"CHECK_FORWARD\": 500,  \n",
    "    \"CHECK_BACKWARD\": 10,  \n",
    "    \"FAILURE_COUNTDOWN\": 10,  \n",
    "    \"MIN_STEPS\": 70,  \n",
    "    \"MAX_STRAY\": 100.0  \n",
    "}\n",
    "\n",
    "La clase RewardFunction se especifíca en tmrl.custom.tm.utils.compute_reward, y en esta se tiene un método compute_reward donde se calcula, primeramente, la distancia entre la posición actual del coche y los puntos de la trayectoria de demostración. En segundo lugar, calcula al recompensa que es el avance en la trayectoria, y si no hay avance, empieza un counter que a FAILURE_COUNTDOWN terminará el episodio. \n",
    "\n",
    "En nuestro caso, CHECK_FORWARD nos define cuantos puntos hacia delante buscar para encontrar coincidencias. CHECK_BACKWARD igual pero mirando hacia atrás. FAILURE_COUNTDOWN nos indica cuantos pasos sin progreso antes de terminar el episodio, siempre que hayan pasado MIN_STEPS en el episodio. MAX_STRAY nos da la distancia máxima permitida de la trayectoria.\n",
    "\n",
    "La trayectoria es la forma en la que TMRL establece su función de recompensa. En vez de fijarse en la velocidad, se graba una trayectoria predefinida en el mapa con anterioridad al entrenamiento, y se establecen unos puntos sobre los cuales calcular la recompensa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20a1cd9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
